{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0a3335",
   "metadata": {},
   "source": [
    "# Cleaning 1.2 - Clean unique values in individual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6f6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator for new variables to be cleaned (default is False, set to True if decide to clean more variables)\n",
    "new_vars_to_clean = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf868fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "CODE_ROOT = Path.cwd().parents[0]\n",
    "sys.path.append(str(CODE_ROOT))\n",
    "import config\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Alignment\n",
    "import os\n",
    "from create_empty_cleaning_sheet import create_empty_cleaning_sheet\n",
    "from unique_values_cleaning import clean_unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c27019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "labs = pd.read_csv(config.PROCESSED_DATA / \"individual_processed_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1237b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data dictionaries\n",
    "other_qs_data_dict = pd.read_excel(config.DATA_DICTIONARIES / \"data_dictionary.xlsx\", sheet_name=\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b27624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or update the excel workbook with empty sheets\n",
    "if new_vars_to_clean:\n",
    "\n",
    "    # File name\n",
    "    file_name = config.CLEANING_WORKBOOKS / \"individual_cleaning_workbook.xlsx\"\n",
    "\n",
    "    # Other questions (one sheet per variable)\n",
    "    for _, row in other_qs_data_dict.iterrows():   \n",
    "        sheet_name = row[\"Variable\"]\n",
    "        comment = row[\"Comment\"] == \"Y\"\n",
    "        free_text = row[\"Free text\"] == \"Y\"\n",
    "        create_empty_cleaning_sheet(file_name, sheet_name, comment, free_text)\n",
    "\n",
    "    # Checklist variables (one sheet for all)\n",
    "    create_empty_cleaning_sheet(file_name, \"Checklist\", comment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d46071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drutna/Library/CloudStorage/OneDrive-UniversitätZürichUZH/lab-experiment/1_Cleaning/unique_values_cleaning.py:70: UserWarning: Parsing dates in %d.%m.%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  out[\"raw_value\"] = pd.to_datetime(out[\"raw_value\"], errors=\"coerce\").dt.normalize()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning progress for survey_date_bl:\n",
      "Total unique value combinations: 21\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 21\n",
      "Cleaning progress for survey_date_el:\n",
      "Total unique value combinations: 33\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 33\n",
      "Cleaning progress for faculty:\n",
      "Total unique value combinations: 12\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 12\n",
      "Cleaning progress for institute:\n",
      "Total unique value combinations: 84\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 84\n",
      "Cleaning progress for no_researchers:\n",
      "Total unique value combinations: 53\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 53\n",
      "Cleaning progress for no_ft:\n",
      "Total unique value combinations: 25\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 25\n",
      "Cleaning progress for no_pt:\n",
      "Total unique value combinations: 15\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 15\n",
      "Cleaning progress for rooms:\n",
      "Total unique value combinations: 137\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 137\n",
      "Cleaning progress for share_equip_ind:\n",
      "Total unique value combinations: 27\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 27\n",
      "Cleaning progress for share_equip_groups:\n",
      "Total unique value combinations: 100\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 100\n",
      "Cleaning progress for share_space_ind:\n",
      "Total unique value combinations: 21\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 21\n",
      "Cleaning progress for share_space_groups:\n",
      "Total unique value combinations: 97\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 97\n",
      "Cleaning progress for share_space_freq:\n",
      "Total unique value combinations: 19\n",
      "Cleaned combinations: 0\n",
      "Pending combinations: 0\n",
      "Excluded combinations: 0\n",
      "Unchecked combinations: 19\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing required column(s) in main dataset: ['comm_group']. Expected based on settings: ['comm_group']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mclean_unique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfree_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfree_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversitätZürichUZH/lab-experiment/1_Cleaning/unique_values_cleaning.py:81\u001b[0m, in \u001b[0;36mclean_unique_values\u001b[0;34m(df, file_name, var_name, sheet_name, dtype, comment, free_text, mc_fc_vars, report)\u001b[0m\n\u001b[1;32m     79\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m required_source_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required column(s) in main dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected based on settings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired_source_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Rename relevant cols in main dataset to match cleaning sheet for merging\u001b[39;00m\n\u001b[1;32m     87\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39mrename_dict)\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mValueError\u001b[0m: Missing required column(s) in main dataset: ['comm_group']. Expected based on settings: ['comm_group']"
     ]
    }
   ],
   "source": [
    "# Run cleaning loop. This will: \n",
    "# 1. Merge our data to the cleaning workbook\n",
    "# 2. Create cleaned variables\n",
    "# 3. produce a report of the cleaning process\n",
    "# 4. Update the cleaning workbook with all uncleaned values\n",
    "\n",
    "file_name = config.CLEANING_WORKBOOKS / \"individual_cleaning_workbook.xlsx\"\n",
    "\n",
    "# Other questions (one sheet per variable)\n",
    "for _, row in other_qs_data_dict.iterrows():\n",
    "    var_name = row[\"Variable\"]\n",
    "    sheet_name = var_name\n",
    "    comment = row[\"Comment\"] == \"Y\"\n",
    "    free_text = row[\"Free text\"] == \"Y\"\n",
    "    if row[\"Numeric\"] == \"Y\":\n",
    "        dtype = \"numeric\"\n",
    "    elif row[\"Date\"] == \"Y\":\n",
    "        dtype = \"date\"\n",
    "    else:\n",
    "        dtype = \"string\"\n",
    "    clean_unique_values(df=labs, file_name=file_name, sheet_name=sheet_name, var_name=var_name, \n",
    "                        comment=comment, free_text=free_text, dtype=dtype, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f57c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labrct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
